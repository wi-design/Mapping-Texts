<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<title>mapping texts/texas</title>
	
	<meta name="viewport" content="width=device-width">
	<meta name="author" content="Wi-Design, Inc. info@wi-design.com">
	<meta name="description" content="Visualizaton tool conducted by Stanford University (Bill Lane Center for the American West) and University of North Texas that plots language patterns 232,567 pages of historical Texas newspapers, as they evolved over time and space">
	<meta name="keywords" content="text-mining, language patterns, language analysis, geospatial, word counts, named entities, topic models, historical, Texas, newspapers">

	<!-- css compile start -->
	<link rel="stylesheet" href="static/css/style.css">
	<!-- css compile stop -->
	
	<!-- Google map api
	 using my API key -->
	<script type="text/javascript" src="http://maps.googleapis.com/maps/api/js?key=AIzaSyBpY7LNXm_rYk7I7wU6HxhKFir40Env3T8&sensor=false"></script>
	
	<!--<script src="static/js/libs/modernizr-2.5.3.min.js"></script>-->
	
	<!-- js concat start -->
	<script src="static/js/libs/jquery-1.7.1.min.js"></script>
	<script src="static/js/libs/jquery-ui-1.7.1.custom.min.js"></script>

	<script src="static/js/libs/d3.v2.min.js"></script>
	
	<script src="static/js/libs/json2.js"></script>
	<script src="static/js/libs/underscore-1.3.1.min.js"></script>
	<script src="static/js/libs/mustache.js"></script>
	
	<script src="static/js/libs/backbone-0.9.1.min.js"></script>
	
	<script src="static/js/plugins/jquery.zclip.min.js"></script>
	<script src="static/js/plugins/modal.js"></script>
	<script src="static/js/plugins/mask.js"></script>
	<script src="static/js/plugins/tooltip.js"></script>
	<script src="static/js/equal_heights.js"></script>
	<script src="static/js/plugins/jquery.checkbox.all.js"></script>
	<script src="static/js/plugins/tabs.js"></script>
	
	<script src="static/js/plugins/selectToUISlider.jQuery.js"></script>
	<!-- js concat stop -->
	
	
	<!-- js ignore start -->
	<!-- js ignore stop -->
		
	<!-- js compile start -->
	<script src="static/js/app.global.namespace.js"></script>

	<script src="static/js/backbone/models/wcc.js"></script>
	<script src="static/js/backbone/models/ner.js"></script>
	<script src="static/js/backbone/models/city.js"></script>
	<script src="static/js/backbone/models/publication.js"></script>
	<script src="static/js/backbone/models/epoch.js"></script>
	
	<script src="static/js/backbone/collections/wcc.js"></script>
	<script src="static/js/backbone/collections/ner.js"></script>
	<script src="static/js/backbone/collections/pub.js"></script>
	<script src="static/js/backbone/collections/publication.js"></script>
	<script src="static/js/backbone/collections/epoch.js"></script>
	<script src="static/js/backbone/collections/topics.js"></script>
	
	<script src="static/js/backbone/views/app.js"></script>
	<script src="static/js/backbone/views/wcc_view.js"></script>
	<script src="static/js/backbone/views/ner_view.js"></script>
	<script src="static/js/backbone/views/topic_view.js"></script>
	<script src="static/js/backbone/views/map_view.js"></script>
	<script src="static/js/backbone/views/pub_view.js"></script>
	<script src="static/js/backbone/views/time_select_view.js"></script>
	<script src="static/js/backbone/views/city_view.js"></script>
	<!-- js compile stop -->
	
	<script>
		$(function(){
			var start_app = function(config) {
				var c = STANFORD.MAPPING_TEXTS.cached;
				
				STANFORD.MAPPING_TEXTS.config = config;
				
				c.epochs = new STANFORD.MAPPING_TEXTS.collections.epochs( config.epochs );
		
				
				c.app = new STANFORD.MAPPING_TEXTS.views.app;
				c.app.render();
			};
			
			
			// ----
			$.getJSON('/config', function(config) { start_app(config); });			
		});

	</script>
	<script>

	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-31223975-1']);
	  _gaq.push(['_trackPageview']);

	  (function() {
	    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
	    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
	    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	  })();

		</script> 
		
</head>

<body>
<header>
	<div class="inner">
		
		<h1>
			<a href="http://mappingtexts.org/" target="_blank" class="branding">
				<span class="screen-reader-text">MappingTexts - Stanford University and University of North Texas</span>
			</a>
		</h1>
	
	</div>
</header>

	<div class="body">
		
		<div class="inner">
			
			<div class="row">	
				<section id="app-ds-view" class="span-full" data-toggle="height">
					<h2>Assessing Language Patterns: <small>A Look at Texas Newspapers, 1829-2008</small></h2>
			
					<p>This visualization plots the language patterns embedded in 232,567 pages of historical Texas newspapers, as they evolved over time and space. For any date range and location, you can browse the most common words (word counts), named entities (people, places, etc), and highly correlated words (topic models). [ <a data-modal-box="#about">About Mapping Texts</a> ]</p>
					
					<!-- About Modal -->
					<div class="modal description" id="about">
						<div class="modal-hd">
							<h2>About this Project</h2>
						</div><!-- /modal-hd -->
						
						<div class="modal-bd">
							<p>“<strong>Mapping Texts</strong>” is a collaborative project between the University of North Texas and Stanford University whose goal has been to develop a series of experimental new models for combining the possibilities of text-mining and geospatial analysis in order to enable researchers to develop better methods for finding and analyzing meaningful language patterns embedded within massive collections of historical newspapers.</p>

							<p>This visualization plots the language patterns embedded in 232,567 pages of historical Texas newspapers, as they evolved over time and space. Using the date range slider to select any time period and the map of Texas to select any combination of locations, you can browse through three major categories of the newspapers’ language patterns: most common words (word counts), named entities (people, places, etc), and highly correlated words (topic models).</p>

							<p>For more information see the project’s main site: <a href="http://www.mappingtexts.org" target="_blank">mapping texts</a>. For more information about the language analysis categories, explore the “<strong>about</strong>” link on each category below.</p>
						</div><!-- /modal-bd -->
					</div>
					<!-- /about modal -->
					
				</section>
			</div><!-- /row -->
			
			<div class="row">
				<section id="time-select-view" class="span-full"></section>
			</div>
				
			<div class="row">
				<section id="map-view" class="span-66pct">
					<div class="map-view widget basic tool"></div>
				</section>
				<section id="pub-view" class="span-33pct">
					<div class="pub-view widget basic tool"></div>
				</section>
			</div><!-- /row -->
			
			<div class="row">
				<section id="wcc-view" class="span-33pct"></section>
				<section id="ner-view" class="span-33pct"></section>
				<section id="topic-view" class="span-33pct"></section>
			</div><!-- /row -->
		
		</div> <!-- /inner -->
		
	</div> <!-- /body -->
	
	<footer class="footer">
		<div class="inner clearfix">
			<p><small>&copy;2011 Stanford University and The University of North Texas</small></p>
			<p>Project Partners: <a href="http://west.stanford.edu/" target="_blank">Bill Lane Center for the American West</a> and <a href="http://texashistory.unt.edu/" target="_blank">Texas Digital Newspaper Collection</a></p>
			<p>Interface designed and built by <a href="http://wi-design.com" target="_blank">Wi-Design, Inc.</a></p>
		</div>
	</footer>

<!--==================================================== modal dialogs ====================================================-->
	
	<div id="word-counts-info" class="modal description">
		<div class="modal-hd">
			<h2>About for Word Counts</h2> 
		</div>
		<div class="modal-bd">	
			<p>Word counts are one of the most widely used metrics for assessing language use in texts. For any given date range and set of locations that you select, you will see a ranked tally of the most frequently appearing words in the newspapers. You can choose between viewing these counts as either a ranked list or a word cloud.</p>

			<p>You can see these word counts for any time period, and for any combination of individual cities or newspapers available during the years you select.</p>

			<p>In generating our word counts, we have removed "stop words," which are commonly appearing terms--such as "a" "the" "and" and "but"--that by themselves have little meaning, but nonetheless appear quite frequently. This is a common technique in natural language processing, and is intended to help expose the most frequently appearing words that do have some useful meaning.</p>

			<p>Because our collection of digitized newspapers contains some "noise" from the digitization process (that is, scanned words were mistakenly jumbled by the computer during the transition from an image to electronic text), sometimes nonsensical words appear in the word count lists (such as "nnd" for "and"). For more on the digitization quality of the newspapers see "<a href="http://mappingtexts.org/quality" target="_blank">Assessing Newspaper Quality</a>" and our <a href="http://mappingtexts.org/whitepaper" target="_blank">White Paper</a>.</p>
		</div>
	</div>
	<!-- /word-counts-info -->
	
	<div id="named-entity-info" class="modal description">
		<div class="modal-hd">
			<h2>About the Named Entity Counts</h2>
		</div>
		<div class="modal-bd">
			<p>Named entity counts are counts of all the particular “entities” (things that are usually considered nouns, like people or places), which are counted and tallied just like basic word counts.</p>

			<p>For any given date range and set of locations that you select, you will see an ranked tally of the most frequently appearing named entities in the newspapers. You can choose between viewing these counts as either a ranked list or a word cloud.</p>

			<p>You can see these word counts for any time period, and for any combination of individual cities or newspapers available during the years you select.</p>

			<p>In order to identify the named entities in each set of newspapers, we used the the Stanford Named Entity Recognizer (<a href="http://www-nlp.stanford.edu/software/CRF-NER.shtml" target="_blank">http://www-nlp.stanford.edu/software/CRF-NER.shtml</a>) because during our testing of various potential parsers the Stanford NER outperformed all others in terms of accuracy, while also maintaining a processing speed comparable with other taggers considered.</p>

			<p>Because our collection of digitized newspapers contains some "noise" from the digitization process (that is, scanned words were mistakenly jumbled by the computer during the transition from an image to electronic text), sometimes nonsensical words appear in the word count lists (such as "nnd" for "and"). For more on the digitization quality of the newspapers see "<a href="http://mappingtexts.org/quality" target="_blank">Assessing Newspaper Quality</a>" and our <a href="http://mappingtexts.org/whitepaper" target="_blank">White Paper</a>.</p>
		</div>
	</div>
	<!-- /named-entity-info -->
	
	<div id="topic-modeling-info" class="modal description">
		<div class="modal-hd">
			<h2>About the Topic Modeling</h2>
		</div>
		<div class="modal-bd">
			<p>Topic modeling is a method of text-analysis has grown in popularity among humanities scholars in recent years. The basic concept is to use statistical methods to uncover connections between collections of words (which are called “topics”) that appear in a given text.</p>

			<p>So, for example, running a topic modeling program over a body of text will produce a series of “topics,” which are strings of words (such as “texas, street, address, good, wanted, Houston, office”) that may not necessarily appear next to one another within the text but nonetheless appear to have a statistical relationship to one another. Topic modeling, in other words, uses statistics to produce lists of words that appear to be highly correlated to one another in the hope of exposing larger, wider patterns in language use than a close-reading would be able to provide.</p>

			<p>For good overviews of what topic modeling is and how it has been used in the humanities, we recommend reading "<a href="http://mith.umd.edu/topic-modeling-in-the-humanities-an-overview/" target="_blank">Topic Modeling in the Humanities: An Overview</a>," "<a href="http://tedunderwood.wordpress.com/2012/04/07/topic-modeling-made-just-simple-enough/" target="_blank">Topic Modeling Made Just Simple Enough</a>," and "<a href="http://www.stanford.edu/~mjockers/cgi-bin/drupal/node/61" target="_blank">The LDA Buffet is Now Open; or, Latent Dirichlet Allocation for English Majors</a>."</p>

			<p>For our topic modeling work, we used the popular University of Massachusetts’s MALLET package (<a href="http://mallet.cs.umass.edu/" target="_blank">http://mallet.cs.umass.edu/</a>). Because topic models are customized for particular collections of text, we divided up our topic models by commonly recognized eras from Texas history: 1829-1835 (Mexican Era), 1836-1845 (Republic of Texas), 1846-1860 (Antebellum Era), 1861-1865 (Civil War), 1866-1877 (Reconstruction), 1878-1899 (Gilded Age), 1900-1929 (Progressive Era), 1930-1941 (Depression), 1942-1945 (World War II), 1946-2008 (Modern Texas).</p>

			<p>For every one one of those eras, we used MALLET to generate the top ten topics, with 100 words per topic for all Texas newspapers from that era. We also generated topics for each Texas city during those eras, so you can explore topic models either region-wide or drill down to individual cities.</p>

			<p>These topics represent "statistical themes" that the MALLET program detects in the newspaper collections. The words in each topic appear in ranked order--that is, the first word in a collection of 100 is the most relevant, the second word the second-most relevant, and so on. (One way to think about this would be to consider the words in a topic to be magentic to one another, with the first word being the most magnetic, the second word the second-most magentic, and so forth.)</p>

			<p>Sometimes the topic is a collection of nonsensical words (like “anu, ior, ethe, ahd, uui, auu, tfie” and so on), when the algorithm found a common thread among the “noise” (that is, words that were jumbled by the digitization process) and recognized a commonality between these non-words, which it then grouped into a “topic.”</p>

			<p>More often, however, the topic models group together words that have a clear relationship to one another. If, for example, you were to select all the newspapers from the Republic of Texas era, one of the topic models offered includes “Texas, government, country, states, united, people, mexico, great, war . . . “ which seems to suggest that a highly relevant theme in the newspapers during this era were the international disputes between the United States and Mexico over the future of the Texas region (and the threat of war that came with that). What is even more revealing, however, is that most of the other topic models suggest that this was only one-—and perhaps even a lesser-—concern than other issues within the newspapers of 1830s and 1840s Texas, such as matters of the local economy (“sale, cotton, Houston, received, boxes, Galveston”), local government (“county, court, land, notice, persons, estate”), and social concerns (“man, time, men, great, life”).</p>
		</div>
	</div>
	<!-- /topic-modeling-info -->
	
<!--==================================================== /modal dialogs ====================================================-->
	
</body>

</html>
